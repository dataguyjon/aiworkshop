{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification - Five Layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data as mnist_data\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# download train and test data (28x28 images of handwritten digits)\n",
    "mnist = mnist_data.read_data_sets(\"data\", one_hot=True, reshape=False, validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input X: 28x28 grayscale images, the first dimension (None) will index the images in the mini-batch\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "\n",
    "# correct answers will go here\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights\n",
    "W1 = tf.Variable(tf.truncated_normal([784, 200], stddev=0.1))\n",
    "W2 = tf.Variable(tf.truncated_normal([200, 100], stddev=0.1))\n",
    "W3 = tf.Variable(tf.truncated_normal([100, 60], stddev=0.1))\n",
    "W4 = tf.Variable(tf.truncated_normal([60, 30], stddev=0.1))\n",
    "W5 = tf.Variable(tf.truncated_normal([30, 10], stddev=0.1))\n",
    "\n",
    "# biases\n",
    "b1 = tf.Variable(tf.ones([200])/10)\n",
    "b2 = tf.Variable(tf.ones([100])/10)\n",
    "b3 = tf.Variable(tf.ones([60])/10)\n",
    "b4 = tf.Variable(tf.ones([30])/10)\n",
    "b5 = tf.Variable(tf.ones([10])/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the images into a single line of pixels\n",
    "# -1 in the shape definition means \"the only possible dimension that will preserve the number of elements\"\n",
    "XX = tf.reshape(X, [-1, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model\n",
    "Y1 = tf.nn.relu(tf.matmul(XX, W1) + b1)\n",
    "Y2 = tf.nn.relu(tf.matmul(Y1, W2) + b2)\n",
    "Y3 = tf.nn.relu(tf.matmul(Y2, W3) + b3)\n",
    "Y4 = tf.nn.relu(tf.matmul(Y3, W4) + b4)\n",
    "Z = tf.matmul(Y4, W5) + b5\n",
    "Y = tf.nn.softmax(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z, labels=Y_)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to keep track of max accuracy\n",
    "max_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(0.003).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "train_loss_log = []\n",
    "test_loss_log = []\n",
    "train_accuracy_log = []\n",
    "test_accuracy_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(i):\n",
    "\n",
    "    global max_accuracy\n",
    "    # training on batches of 100 images with 100 labels\n",
    "    batch_X, batch_Y = mnist.train.next_batch(100)\n",
    "\n",
    "    # compute training values\n",
    "    if (i % 10 == 0):\n",
    "        a, c = sess.run([accuracy, cross_entropy], feed_dict={X: batch_X, Y_: batch_Y})\n",
    "        train_accuracy_log.append([i,a])\n",
    "        train_loss_log.append([i,c])        \n",
    "        print(str(i) + \": accuracy:\" + str(a) + \" loss: \" + str(c))\n",
    "\n",
    "    # compute test values\n",
    "    if (i % 50 == 0):\n",
    "        a, c = sess.run([accuracy, cross_entropy], feed_dict={X: mnist.test.images, Y_: mnist.test.labels})\n",
    "        test_accuracy_log.append([i,a])\n",
    "        test_loss_log.append([i,c])  \n",
    "        if (a > max_accuracy):\n",
    "            max_accuracy = a\n",
    "\n",
    "        print(str(i) + \": $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:\" + str(a) + \" test loss: \" + str(c))\n",
    "\n",
    "    # the backpropagation training step\n",
    "    sess.run(train_step, feed_dict={X: batch_X, Y_: batch_Y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: accuracy:0.11 loss: 230.03162\n",
      "0: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.0865 test loss: 230.55315\n",
      "10: accuracy:0.53 loss: 145.26956\n",
      "20: accuracy:0.75 loss: 87.923294\n",
      "30: accuracy:0.8 loss: 66.78097\n",
      "40: accuracy:0.84 loss: 51.94828\n",
      "50: accuracy:0.88 loss: 43.808075\n",
      "50: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.8856 test loss: 40.015835\n",
      "60: accuracy:0.9 loss: 34.331467\n",
      "70: accuracy:0.88 loss: 34.721905\n",
      "80: accuracy:0.91 loss: 34.80722\n",
      "90: accuracy:0.9 loss: 33.133865\n",
      "100: accuracy:0.99 loss: 11.732085\n",
      "100: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9213 test loss: 28.030703\n",
      "110: accuracy:0.86 loss: 45.301582\n",
      "120: accuracy:0.86 loss: 47.881516\n",
      "130: accuracy:0.96 loss: 16.43459\n",
      "140: accuracy:0.96 loss: 21.749535\n",
      "150: accuracy:0.93 loss: 19.698385\n",
      "150: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9183 test loss: 26.36386\n",
      "160: accuracy:0.94 loss: 19.728401\n",
      "170: accuracy:0.88 loss: 29.120564\n",
      "180: accuracy:0.9 loss: 40.86673\n",
      "190: accuracy:0.9 loss: 30.414587\n",
      "200: accuracy:0.91 loss: 33.049652\n",
      "200: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9407 test loss: 19.675121\n",
      "210: accuracy:0.95 loss: 18.256971\n",
      "220: accuracy:0.91 loss: 32.01524\n",
      "230: accuracy:0.9 loss: 31.648005\n",
      "240: accuracy:0.92 loss: 29.008299\n",
      "250: accuracy:0.92 loss: 25.285778\n",
      "250: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9322 test loss: 21.833715\n",
      "260: accuracy:0.94 loss: 16.214273\n",
      "270: accuracy:0.88 loss: 34.518955\n",
      "280: accuracy:0.91 loss: 29.724014\n",
      "290: accuracy:0.95 loss: 18.400581\n",
      "300: accuracy:0.95 loss: 22.373522\n",
      "300: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.947 test loss: 17.55201\n",
      "310: accuracy:0.95 loss: 11.681954\n",
      "320: accuracy:0.95 loss: 15.411982\n",
      "330: accuracy:0.97 loss: 13.763681\n",
      "340: accuracy:0.96 loss: 16.605425\n",
      "350: accuracy:0.95 loss: 9.772897\n",
      "350: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9553 test loss: 14.47283\n",
      "360: accuracy:0.95 loss: 11.311884\n",
      "370: accuracy:0.95 loss: 21.55365\n",
      "380: accuracy:0.98 loss: 11.034338\n",
      "390: accuracy:0.96 loss: 20.541168\n",
      "400: accuracy:0.94 loss: 18.057398\n",
      "400: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9462 test loss: 16.653355\n",
      "410: accuracy:0.95 loss: 14.774368\n",
      "420: accuracy:0.96 loss: 11.416864\n",
      "430: accuracy:0.93 loss: 12.929821\n",
      "440: accuracy:0.99 loss: 11.004596\n",
      "450: accuracy:0.95 loss: 16.959991\n",
      "450: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9585 test loss: 14.024387\n",
      "460: accuracy:0.97 loss: 9.403551\n",
      "470: accuracy:0.95 loss: 21.305145\n",
      "480: accuracy:0.96 loss: 15.318579\n",
      "490: accuracy:0.93 loss: 12.991233\n",
      "500: accuracy:0.94 loss: 18.785223\n",
      "500: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9515 test loss: 16.41659\n",
      "510: accuracy:0.96 loss: 10.513508\n",
      "520: accuracy:0.94 loss: 21.790197\n",
      "530: accuracy:0.97 loss: 15.561263\n",
      "540: accuracy:0.97 loss: 8.660358\n",
      "550: accuracy:0.95 loss: 8.445007\n",
      "550: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9623 test loss: 12.79779\n",
      "560: accuracy:0.96 loss: 13.765528\n",
      "570: accuracy:0.96 loss: 10.964138\n",
      "580: accuracy:0.96 loss: 15.994196\n",
      "590: accuracy:0.94 loss: 25.79015\n",
      "600: accuracy:0.94 loss: 16.773628\n",
      "600: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9517 test loss: 14.897126\n",
      "610: accuracy:0.97 loss: 7.6863966\n",
      "620: accuracy:0.97 loss: 9.772766\n",
      "630: accuracy:0.96 loss: 10.819983\n",
      "640: accuracy:0.96 loss: 15.111574\n",
      "650: accuracy:0.93 loss: 21.651253\n",
      "650: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9566 test loss: 14.725107\n",
      "660: accuracy:0.96 loss: 14.621468\n",
      "670: accuracy:0.97 loss: 8.565683\n",
      "680: accuracy:0.98 loss: 8.732846\n",
      "690: accuracy:0.98 loss: 11.373521\n",
      "700: accuracy:0.94 loss: 13.711922\n",
      "700: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9637 test loss: 11.466147\n",
      "710: accuracy:0.99 loss: 1.8619329\n",
      "720: accuracy:0.97 loss: 7.9422064\n",
      "730: accuracy:0.96 loss: 12.974498\n",
      "740: accuracy:0.98 loss: 6.9187\n",
      "750: accuracy:0.95 loss: 12.094669\n",
      "750: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9618 test loss: 12.712097\n",
      "760: accuracy:0.95 loss: 25.268179\n",
      "770: accuracy:0.96 loss: 6.4760184\n",
      "780: accuracy:0.99 loss: 5.764403\n",
      "790: accuracy:0.94 loss: 19.287678\n",
      "800: accuracy:0.96 loss: 17.306856\n",
      "800: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9578 test loss: 13.827825\n",
      "810: accuracy:0.96 loss: 11.434137\n",
      "820: accuracy:0.97 loss: 8.897758\n",
      "830: accuracy:0.98 loss: 6.4528317\n",
      "840: accuracy:0.98 loss: 11.512214\n",
      "850: accuracy:0.98 loss: 11.762309\n",
      "850: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9626 test loss: 12.399812\n",
      "860: accuracy:0.99 loss: 6.88358\n",
      "870: accuracy:0.94 loss: 11.92162\n",
      "880: accuracy:0.97 loss: 7.245962\n",
      "890: accuracy:0.97 loss: 11.975541\n",
      "900: accuracy:0.98 loss: 5.0308\n",
      "900: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9681 test loss: 9.881006\n",
      "910: accuracy:0.94 loss: 11.48463\n",
      "920: accuracy:0.99 loss: 4.2227044\n",
      "930: accuracy:0.97 loss: 9.471557\n",
      "940: accuracy:0.96 loss: 14.835564\n",
      "950: accuracy:0.97 loss: 14.822737\n",
      "950: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9694 test loss: 10.353674\n",
      "960: accuracy:0.97 loss: 9.845051\n",
      "970: accuracy:0.98 loss: 5.4250255\n",
      "980: accuracy:0.94 loss: 21.11307\n",
      "990: accuracy:0.97 loss: 7.740802\n",
      "1000: accuracy:1.0 loss: 1.0935736\n",
      "1000: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.969 test loss: 9.897585\n",
      "1010: accuracy:0.95 loss: 18.255133\n",
      "1020: accuracy:0.96 loss: 9.532286\n",
      "1030: accuracy:0.98 loss: 4.615449\n",
      "1040: accuracy:0.96 loss: 14.336282\n",
      "1050: accuracy:0.93 loss: 24.207413\n",
      "1050: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9661 test loss: 11.521267\n",
      "1060: accuracy:0.98 loss: 6.601931\n",
      "1070: accuracy:0.94 loss: 18.04722\n",
      "1080: accuracy:0.9 loss: 24.520147\n",
      "1090: accuracy:0.99 loss: 4.881967\n",
      "1100: accuracy:0.97 loss: 12.028224\n",
      "1100: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9628 test loss: 12.24836\n",
      "1110: accuracy:0.97 loss: 12.109571\n",
      "1120: accuracy:0.94 loss: 14.948313\n",
      "1130: accuracy:0.98 loss: 5.8110137\n",
      "1140: accuracy:0.97 loss: 13.608962\n",
      "1150: accuracy:0.99 loss: 2.9422605\n",
      "1150: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9678 test loss: 10.758332\n",
      "1160: accuracy:0.98 loss: 9.931485\n",
      "1170: accuracy:0.98 loss: 4.823\n",
      "1180: accuracy:0.96 loss: 11.389241\n",
      "1190: accuracy:0.99 loss: 4.6042404\n",
      "1200: accuracy:0.98 loss: 7.721781\n",
      "1200: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9724 test loss: 9.224483\n",
      "1210: accuracy:0.97 loss: 9.8271\n",
      "1220: accuracy:0.98 loss: 6.5012207\n",
      "1230: accuracy:0.99 loss: 5.1665\n",
      "1240: accuracy:0.94 loss: 15.46081\n",
      "1250: accuracy:0.97 loss: 9.55007\n",
      "1250: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9715 test loss: 9.262993\n",
      "1260: accuracy:1.0 loss: 1.4298074\n",
      "1270: accuracy:0.99 loss: 5.9168363\n",
      "1280: accuracy:0.97 loss: 8.938392\n",
      "1290: accuracy:0.99 loss: 4.366254\n",
      "1300: accuracy:0.97 loss: 8.411051\n",
      "1300: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9697 test loss: 9.914606\n",
      "1310: accuracy:0.97 loss: 12.617272\n",
      "1320: accuracy:0.98 loss: 4.7128716\n",
      "1330: accuracy:0.95 loss: 13.2571745\n",
      "1340: accuracy:0.97 loss: 13.074319\n",
      "1350: accuracy:0.98 loss: 4.9514966\n",
      "1350: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9683 test loss: 10.169845\n",
      "1360: accuracy:0.98 loss: 7.6181097\n",
      "1370: accuracy:1.0 loss: 1.2092083\n",
      "1380: accuracy:0.98 loss: 7.9811654\n",
      "1390: accuracy:0.97 loss: 5.58417\n",
      "1400: accuracy:0.99 loss: 7.9841943\n",
      "1400: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9721 test loss: 9.365223\n",
      "1410: accuracy:0.98 loss: 6.0308547\n",
      "1420: accuracy:0.98 loss: 3.416721\n",
      "1430: accuracy:0.99 loss: 4.4589257\n",
      "1440: accuracy:0.98 loss: 6.4445486\n",
      "1450: accuracy:0.96 loss: 9.289248\n",
      "1450: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9688 test loss: 10.678201\n",
      "1460: accuracy:0.99 loss: 2.0162668\n",
      "1470: accuracy:0.98 loss: 10.526621\n",
      "1480: accuracy:1.0 loss: 1.548138\n",
      "1490: accuracy:0.97 loss: 13.435795\n",
      "1500: accuracy:0.95 loss: 10.649173\n",
      "1500: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9736 test loss: 9.309188\n",
      "1510: accuracy:0.98 loss: 5.804892\n",
      "1520: accuracy:1.0 loss: 1.1846336\n",
      "1530: accuracy:0.98 loss: 5.341471\n",
      "1540: accuracy:0.97 loss: 9.459336\n",
      "1550: accuracy:0.97 loss: 7.225996\n",
      "1550: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9729 test loss: 9.679532\n",
      "1560: accuracy:0.96 loss: 6.7371426\n",
      "1570: accuracy:0.99 loss: 5.083507\n",
      "1580: accuracy:0.99 loss: 3.1525548\n",
      "1590: accuracy:0.97 loss: 11.046454\n",
      "1600: accuracy:0.99 loss: 4.751361\n",
      "1600: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9702 test loss: 9.645744\n",
      "1610: accuracy:1.0 loss: 1.1744758\n",
      "1620: accuracy:0.98 loss: 4.536331\n",
      "1630: accuracy:0.96 loss: 12.526324\n",
      "1640: accuracy:0.97 loss: 12.196306\n",
      "1650: accuracy:0.98 loss: 5.5980706\n",
      "1650: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9709 test loss: 10.290968\n",
      "1660: accuracy:0.98 loss: 7.803855\n",
      "1670: accuracy:0.98 loss: 8.330298\n",
      "1680: accuracy:0.99 loss: 4.9514766\n",
      "1690: accuracy:0.99 loss: 2.9040468\n",
      "1700: accuracy:0.98 loss: 6.6766596\n",
      "1700: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9732 test loss: 8.886285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710: accuracy:0.97 loss: 7.839624\n",
      "1720: accuracy:0.96 loss: 7.484924\n",
      "1730: accuracy:0.98 loss: 6.0785666\n",
      "1740: accuracy:0.94 loss: 16.25582\n",
      "1750: accuracy:0.97 loss: 7.470943\n",
      "1750: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9694 test loss: 10.400341\n",
      "1760: accuracy:0.96 loss: 7.752699\n",
      "1770: accuracy:0.95 loss: 10.334173\n",
      "1780: accuracy:0.95 loss: 13.280803\n",
      "1790: accuracy:0.97 loss: 13.913248\n",
      "1800: accuracy:0.99 loss: 3.6269736\n",
      "1800: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.972 test loss: 8.941671\n",
      "1810: accuracy:0.98 loss: 3.7207637\n",
      "1820: accuracy:0.99 loss: 1.4003997\n",
      "1830: accuracy:1.0 loss: 1.1288452\n",
      "1840: accuracy:0.98 loss: 2.4797041\n",
      "1850: accuracy:0.98 loss: 3.6969993\n",
      "1850: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9754 test loss: 8.459363\n",
      "1860: accuracy:0.99 loss: 4.2257776\n",
      "1870: accuracy:0.99 loss: 2.8369703\n",
      "1880: accuracy:0.96 loss: 8.0947895\n",
      "1890: accuracy:0.99 loss: 8.6291275\n",
      "1900: accuracy:0.98 loss: 6.689523\n",
      "1900: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9717 test loss: 10.390356\n",
      "1910: accuracy:1.0 loss: 2.3543184\n",
      "1920: accuracy:1.0 loss: 1.1361108\n",
      "1930: accuracy:0.97 loss: 6.135369\n",
      "1940: accuracy:0.99 loss: 6.814865\n",
      "1950: accuracy:0.96 loss: 11.021959\n",
      "1950: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9709 test loss: 10.04334\n",
      "1960: accuracy:1.0 loss: 2.0563445\n",
      "1970: accuracy:0.97 loss: 6.3443704\n",
      "1980: accuracy:0.98 loss: 7.634976\n",
      "1990: accuracy:0.98 loss: 5.501053\n",
      "2000: accuracy:0.98 loss: 12.907017\n",
      "2000: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.975 test loss: 8.636243\n",
      "2010: accuracy:0.97 loss: 18.20547\n",
      "2020: accuracy:0.97 loss: 4.4406557\n",
      "2030: accuracy:0.96 loss: 5.200459\n",
      "2040: accuracy:0.98 loss: 7.0974216\n",
      "2050: accuracy:0.97 loss: 12.721832\n",
      "2050: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.972 test loss: 8.926428\n",
      "2060: accuracy:0.99 loss: 3.7134123\n",
      "2070: accuracy:1.0 loss: 2.2458012\n",
      "2080: accuracy:0.98 loss: 4.861137\n",
      "2090: accuracy:0.96 loss: 10.752291\n",
      "2100: accuracy:1.0 loss: 2.2644699\n",
      "2100: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9714 test loss: 10.096593\n",
      "2110: accuracy:0.98 loss: 8.800008\n",
      "2120: accuracy:0.97 loss: 8.731598\n",
      "2130: accuracy:0.98 loss: 8.6223\n",
      "2140: accuracy:0.98 loss: 6.778219\n",
      "2150: accuracy:1.0 loss: 1.6829735\n",
      "2150: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9722 test loss: 9.159716\n",
      "2160: accuracy:0.98 loss: 4.441172\n",
      "2170: accuracy:0.96 loss: 11.947892\n",
      "2180: accuracy:0.99 loss: 3.839092\n",
      "2190: accuracy:0.99 loss: 2.8111522\n",
      "2200: accuracy:0.99 loss: 5.5824537\n",
      "2200: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9667 test loss: 10.827951\n",
      "2210: accuracy:0.99 loss: 1.955094\n",
      "2220: accuracy:0.96 loss: 7.4499116\n",
      "2230: accuracy:0.98 loss: 5.03669\n",
      "2240: accuracy:0.98 loss: 7.44863\n",
      "2250: accuracy:0.98 loss: 3.0249305\n",
      "2250: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9761 test loss: 8.326297\n",
      "2260: accuracy:0.99 loss: 4.505311\n",
      "2270: accuracy:0.96 loss: 7.006941\n",
      "2280: accuracy:0.98 loss: 11.590781\n",
      "2290: accuracy:0.98 loss: 7.0747776\n",
      "2300: accuracy:0.96 loss: 8.946653\n",
      "2300: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9729 test loss: 9.870045\n",
      "2310: accuracy:0.99 loss: 1.907894\n",
      "2320: accuracy:0.99 loss: 2.8740115\n",
      "2330: accuracy:0.98 loss: 5.540374\n",
      "2340: accuracy:0.99 loss: 3.7223275\n",
      "2350: accuracy:0.96 loss: 6.7934012\n",
      "2350: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9699 test loss: 10.4624605\n",
      "2360: accuracy:0.98 loss: 7.863572\n",
      "2370: accuracy:0.96 loss: 12.193792\n",
      "2380: accuracy:0.97 loss: 6.909144\n",
      "2390: accuracy:0.99 loss: 2.6459675\n",
      "2400: accuracy:0.96 loss: 11.146338\n",
      "2400: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9743 test loss: 8.81308\n",
      "2410: accuracy:1.0 loss: 1.5800787\n",
      "2420: accuracy:0.96 loss: 11.987707\n",
      "2430: accuracy:0.98 loss: 3.8751733\n",
      "2440: accuracy:0.99 loss: 2.8445938\n",
      "2450: accuracy:0.99 loss: 3.7671316\n",
      "2450: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9774 test loss: 8.463377\n",
      "2460: accuracy:0.97 loss: 4.521792\n",
      "2470: accuracy:0.98 loss: 2.1340542\n",
      "2480: accuracy:1.0 loss: 1.2308011\n",
      "2490: accuracy:1.0 loss: 0.55925244\n",
      "2500: accuracy:1.0 loss: 0.88254714\n",
      "2500: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9762 test loss: 8.309742\n",
      "2510: accuracy:0.99 loss: 3.1141047\n",
      "2520: accuracy:0.99 loss: 2.6877615\n",
      "2530: accuracy:1.0 loss: 0.9320761\n",
      "2540: accuracy:0.98 loss: 5.147947\n",
      "2550: accuracy:1.0 loss: 1.1000748\n",
      "2550: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9765 test loss: 8.357493\n",
      "2560: accuracy:0.97 loss: 8.9337\n",
      "2570: accuracy:0.97 loss: 5.4808803\n",
      "2580: accuracy:0.98 loss: 4.624245\n",
      "2590: accuracy:0.96 loss: 12.3195715\n",
      "2600: accuracy:1.0 loss: 0.7973384\n",
      "2600: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9718 test loss: 10.08026\n",
      "2610: accuracy:0.97 loss: 4.8909106\n",
      "2620: accuracy:1.0 loss: 0.5710755\n",
      "2630: accuracy:0.98 loss: 4.65109\n",
      "2640: accuracy:0.99 loss: 4.3558116\n",
      "2650: accuracy:1.0 loss: 1.577925\n",
      "2650: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9767 test loss: 8.5841465\n",
      "2660: accuracy:0.99 loss: 3.678035\n",
      "2670: accuracy:0.99 loss: 1.7449476\n",
      "2680: accuracy:1.0 loss: 0.96699995\n",
      "2690: accuracy:0.99 loss: 1.4462763\n",
      "2700: accuracy:0.99 loss: 6.9937177\n",
      "2700: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.972 test loss: 10.340009\n",
      "2710: accuracy:0.99 loss: 5.3493943\n",
      "2720: accuracy:0.98 loss: 16.713644\n",
      "2730: accuracy:0.98 loss: 6.4435153\n",
      "2740: accuracy:0.98 loss: 10.51595\n",
      "2750: accuracy:0.96 loss: 8.370302\n",
      "2750: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9732 test loss: 9.677358\n",
      "2760: accuracy:1.0 loss: 1.1263788\n",
      "2770: accuracy:0.97 loss: 7.619879\n",
      "2780: accuracy:1.0 loss: 1.2224337\n",
      "2790: accuracy:0.98 loss: 4.70966\n",
      "2800: accuracy:1.0 loss: 0.49877796\n",
      "2800: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9747 test loss: 9.427506\n",
      "2810: accuracy:0.96 loss: 8.125924\n",
      "2820: accuracy:0.98 loss: 4.375195\n",
      "2830: accuracy:1.0 loss: 0.4881602\n",
      "2840: accuracy:0.98 loss: 3.2838638\n",
      "2850: accuracy:0.99 loss: 4.7386713\n",
      "2850: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9755 test loss: 9.175912\n",
      "2860: accuracy:1.0 loss: 0.60538334\n",
      "2870: accuracy:0.97 loss: 12.812534\n",
      "2880: accuracy:0.97 loss: 10.076335\n",
      "2890: accuracy:0.96 loss: 15.273144\n",
      "2900: accuracy:0.99 loss: 5.9278026\n",
      "2900: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9709 test loss: 10.009809\n",
      "2910: accuracy:0.98 loss: 10.920687\n",
      "2920: accuracy:0.98 loss: 5.8726482\n",
      "2930: accuracy:0.98 loss: 5.5073533\n",
      "2940: accuracy:1.0 loss: 1.9353384\n",
      "2950: accuracy:0.98 loss: 4.7828116\n",
      "2950: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9755 test loss: 8.994455\n",
      "2960: accuracy:0.98 loss: 3.987832\n",
      "2970: accuracy:1.0 loss: 0.9836212\n",
      "2980: accuracy:0.98 loss: 11.410902\n",
      "2990: accuracy:0.97 loss: 18.270803\n",
      "3000: accuracy:0.99 loss: 4.5314827\n",
      "3000: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9732 test loss: 9.849867\n",
      "3010: accuracy:0.99 loss: 3.019047\n",
      "3020: accuracy:0.99 loss: 2.6839268\n",
      "3030: accuracy:0.98 loss: 3.7058725\n",
      "3040: accuracy:0.99 loss: 4.695376\n",
      "3050: accuracy:1.0 loss: 1.2299694\n",
      "3050: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9744 test loss: 8.898349\n",
      "3060: accuracy:0.99 loss: 1.9222845\n",
      "3070: accuracy:1.0 loss: 1.4601574\n",
      "3080: accuracy:1.0 loss: 0.88244665\n",
      "3090: accuracy:0.98 loss: 3.8802419\n",
      "3100: accuracy:0.98 loss: 6.380806\n",
      "3100: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9741 test loss: 9.951089\n",
      "3110: accuracy:0.97 loss: 7.163728\n",
      "3120: accuracy:0.98 loss: 4.6288314\n",
      "3130: accuracy:0.99 loss: 5.6525674\n",
      "3140: accuracy:0.98 loss: 5.7263684\n",
      "3150: accuracy:1.0 loss: 0.2451071\n",
      "3150: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.972 test loss: 9.312789\n",
      "3160: accuracy:1.0 loss: 1.0576735\n",
      "3170: accuracy:1.0 loss: 0.8083234\n",
      "3180: accuracy:1.0 loss: 1.3240513\n",
      "3190: accuracy:0.99 loss: 2.7632804\n",
      "3200: accuracy:1.0 loss: 2.066912\n",
      "3200: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9772 test loss: 8.334477\n",
      "3210: accuracy:0.98 loss: 6.268133\n",
      "3220: accuracy:0.96 loss: 18.859747\n",
      "3230: accuracy:0.99 loss: 6.5231466\n",
      "3240: accuracy:1.0 loss: 0.5878745\n",
      "3250: accuracy:0.99 loss: 2.0410752\n",
      "3250: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9766 test loss: 8.784201\n",
      "3260: accuracy:1.0 loss: 1.468183\n",
      "3270: accuracy:0.99 loss: 2.7959971\n",
      "3280: accuracy:0.99 loss: 2.2831907\n",
      "3290: accuracy:0.99 loss: 5.121099\n",
      "3300: accuracy:0.99 loss: 8.371526\n",
      "3300: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9731 test loss: 9.385297\n",
      "3310: accuracy:0.99 loss: 2.5019343\n",
      "3320: accuracy:0.95 loss: 21.929354\n",
      "3330: accuracy:0.99 loss: 2.5456586\n",
      "3340: accuracy:0.99 loss: 3.295484\n",
      "3350: accuracy:0.99 loss: 2.5718975\n",
      "3350: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9779 test loss: 7.877134\n",
      "3360: accuracy:0.99 loss: 1.8593123\n",
      "3370: accuracy:0.98 loss: 4.7529345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3380: accuracy:0.99 loss: 5.826163\n",
      "3390: accuracy:0.97 loss: 8.821605\n",
      "3400: accuracy:0.95 loss: 10.814534\n",
      "3400: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9753 test loss: 8.80538\n",
      "3410: accuracy:0.98 loss: 9.297127\n",
      "3420: accuracy:0.99 loss: 2.3318985\n",
      "3430: accuracy:0.98 loss: 4.5161805\n",
      "3440: accuracy:0.99 loss: 1.7897066\n",
      "3450: accuracy:1.0 loss: 0.73851746\n",
      "3450: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9777 test loss: 7.882453\n",
      "3460: accuracy:0.99 loss: 5.660606\n",
      "3470: accuracy:1.0 loss: 0.80421895\n",
      "3480: accuracy:0.98 loss: 7.683886\n",
      "3490: accuracy:0.97 loss: 4.662051\n",
      "3500: accuracy:1.0 loss: 0.64782286\n",
      "3500: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.975 test loss: 10.105567\n",
      "3510: accuracy:0.97 loss: 8.483677\n",
      "3520: accuracy:1.0 loss: 0.35668144\n",
      "3530: accuracy:1.0 loss: 1.7535429\n",
      "3540: accuracy:1.0 loss: 0.8219835\n",
      "3550: accuracy:1.0 loss: 1.2778085\n",
      "3550: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9726 test loss: 9.477556\n",
      "3560: accuracy:0.98 loss: 6.720469\n",
      "3570: accuracy:1.0 loss: 0.27317584\n",
      "3580: accuracy:0.99 loss: 2.0776412\n",
      "3590: accuracy:0.97 loss: 7.580509\n",
      "3600: accuracy:1.0 loss: 1.3207988\n",
      "3600: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9758 test loss: 8.588664\n",
      "3610: accuracy:0.99 loss: 2.6533508\n",
      "3620: accuracy:1.0 loss: 1.1123464\n",
      "3630: accuracy:0.99 loss: 3.6571133\n",
      "3640: accuracy:0.99 loss: 5.614545\n",
      "3650: accuracy:0.98 loss: 8.478261\n",
      "3650: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9753 test loss: 10.004353\n",
      "3660: accuracy:0.99 loss: 3.237683\n",
      "3670: accuracy:0.97 loss: 6.642996\n",
      "3680: accuracy:1.0 loss: 0.9935414\n",
      "3690: accuracy:0.99 loss: 3.3949032\n",
      "3700: accuracy:0.98 loss: 13.351044\n",
      "3700: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.974 test loss: 10.891098\n",
      "3710: accuracy:0.97 loss: 12.259557\n",
      "3720: accuracy:0.99 loss: 7.728836\n",
      "3730: accuracy:1.0 loss: 0.29752532\n",
      "3740: accuracy:0.99 loss: 2.0369024\n",
      "3750: accuracy:0.98 loss: 4.686448\n",
      "3750: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9752 test loss: 9.1607275\n",
      "3760: accuracy:0.99 loss: 2.3527238\n",
      "3770: accuracy:0.99 loss: 5.3682203\n",
      "3780: accuracy:0.99 loss: 2.252189\n",
      "3790: accuracy:1.0 loss: 0.7762532\n",
      "3800: accuracy:0.99 loss: 2.804172\n",
      "3800: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9761 test loss: 9.464478\n",
      "3810: accuracy:0.98 loss: 4.1520824\n",
      "3820: accuracy:0.99 loss: 2.6305559\n",
      "3830: accuracy:1.0 loss: 1.0519351\n",
      "3840: accuracy:0.98 loss: 9.516352\n",
      "3850: accuracy:0.99 loss: 1.5681766\n",
      "3850: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9743 test loss: 9.534433\n",
      "3860: accuracy:0.98 loss: 10.197204\n",
      "3870: accuracy:0.97 loss: 12.714285\n",
      "3880: accuracy:1.0 loss: 1.1447135\n",
      "3890: accuracy:0.98 loss: 3.1839273\n",
      "3900: accuracy:0.99 loss: 1.6183853\n",
      "3900: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9687 test loss: 12.670213\n",
      "3910: accuracy:0.99 loss: 2.1263688\n",
      "3920: accuracy:1.0 loss: 1.1221101\n",
      "3930: accuracy:1.0 loss: 1.1262312\n",
      "3940: accuracy:0.99 loss: 3.1415389\n",
      "3950: accuracy:0.96 loss: 5.7556605\n",
      "3950: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.976 test loss: 9.017734\n",
      "3960: accuracy:0.99 loss: 5.9001756\n",
      "3970: accuracy:0.98 loss: 3.2606163\n",
      "3980: accuracy:0.98 loss: 8.717886\n",
      "3990: accuracy:1.0 loss: 0.98014075\n",
      "4000: accuracy:0.98 loss: 7.532216\n",
      "4000: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9743 test loss: 9.777017\n",
      "4010: accuracy:0.97 loss: 16.662378\n",
      "4020: accuracy:0.99 loss: 7.054136\n",
      "4030: accuracy:0.96 loss: 8.273345\n",
      "4040: accuracy:0.96 loss: 5.7631907\n",
      "4050: accuracy:0.99 loss: 1.2544652\n",
      "4050: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9773 test loss: 9.1502\n",
      "4060: accuracy:0.97 loss: 7.454243\n",
      "4070: accuracy:0.98 loss: 5.12554\n",
      "4080: accuracy:1.0 loss: 1.368336\n",
      "4090: accuracy:0.99 loss: 4.166764\n",
      "4100: accuracy:0.99 loss: 5.3503785\n",
      "4100: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9736 test loss: 10.226503\n",
      "4110: accuracy:0.96 loss: 13.342303\n",
      "4120: accuracy:0.98 loss: 3.4801955\n",
      "4130: accuracy:0.98 loss: 5.842358\n",
      "4140: accuracy:0.98 loss: 7.9641104\n",
      "4150: accuracy:0.99 loss: 8.258582\n",
      "4150: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9732 test loss: 10.348324\n",
      "4160: accuracy:0.96 loss: 11.360537\n",
      "4170: accuracy:0.97 loss: 4.9659843\n",
      "4180: accuracy:1.0 loss: 1.0215381\n",
      "4190: accuracy:0.99 loss: 5.8251543\n",
      "4200: accuracy:0.99 loss: 2.1001518\n",
      "4200: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9801 test loss: 8.159864\n",
      "4210: accuracy:0.99 loss: 2.43875\n",
      "4220: accuracy:0.98 loss: 7.2921686\n",
      "4230: accuracy:1.0 loss: 0.37506637\n",
      "4240: accuracy:1.0 loss: 0.99613357\n",
      "4250: accuracy:1.0 loss: 0.86998355\n",
      "4250: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9793 test loss: 8.77369\n",
      "4260: accuracy:0.98 loss: 4.0998907\n",
      "4270: accuracy:1.0 loss: 0.21636324\n",
      "4280: accuracy:0.98 loss: 4.468155\n",
      "4290: accuracy:0.98 loss: 2.349141\n",
      "4300: accuracy:1.0 loss: 0.7602882\n",
      "4300: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.978 test loss: 8.910861\n",
      "4310: accuracy:0.99 loss: 1.4134804\n",
      "4320: accuracy:1.0 loss: 0.60857487\n",
      "4330: accuracy:0.99 loss: 2.459869\n",
      "4340: accuracy:0.99 loss: 2.658729\n",
      "4350: accuracy:1.0 loss: 0.10931712\n",
      "4350: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.981 test loss: 8.162395\n",
      "4360: accuracy:1.0 loss: 0.33803615\n",
      "4370: accuracy:0.98 loss: 2.5297928\n",
      "4380: accuracy:0.98 loss: 6.3495145\n",
      "4390: accuracy:1.0 loss: 0.6354113\n",
      "4400: accuracy:1.0 loss: 1.5866009\n",
      "4400: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9809 test loss: 7.9294863\n",
      "4410: accuracy:0.97 loss: 4.0634227\n",
      "4420: accuracy:0.99 loss: 2.4435616\n",
      "4430: accuracy:0.99 loss: 5.3400435\n",
      "4440: accuracy:0.99 loss: 3.4496188\n",
      "4450: accuracy:1.0 loss: 0.18776372\n",
      "4450: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9771 test loss: 10.019785\n",
      "4460: accuracy:0.99 loss: 2.5338435\n",
      "4470: accuracy:0.96 loss: 22.89171\n",
      "4480: accuracy:0.99 loss: 6.7717304\n",
      "4490: accuracy:1.0 loss: 0.28520903\n",
      "4500: accuracy:1.0 loss: 0.92472273\n",
      "4500: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9726 test loss: 11.272608\n",
      "4510: accuracy:0.96 loss: 6.597695\n",
      "4520: accuracy:0.99 loss: 3.3277307\n",
      "4530: accuracy:0.98 loss: 7.300949\n",
      "4540: accuracy:0.99 loss: 7.207412\n",
      "4550: accuracy:0.99 loss: 1.6963348\n",
      "4550: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9759 test loss: 9.707219\n",
      "4560: accuracy:1.0 loss: 0.48511043\n",
      "4570: accuracy:0.99 loss: 1.3227665\n",
      "4580: accuracy:1.0 loss: 0.1437065\n",
      "4590: accuracy:1.0 loss: 1.5500537\n",
      "4600: accuracy:0.98 loss: 2.2390668\n",
      "4600: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9751 test loss: 9.944735\n",
      "4610: accuracy:0.99 loss: 10.900229\n",
      "4620: accuracy:1.0 loss: 0.6982111\n",
      "4630: accuracy:0.99 loss: 2.2619033\n",
      "4640: accuracy:1.0 loss: 0.27111983\n",
      "4650: accuracy:0.99 loss: 4.044817\n",
      "4650: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9792 test loss: 8.612829\n",
      "4660: accuracy:1.0 loss: 0.3048645\n",
      "4670: accuracy:0.98 loss: 2.663387\n",
      "4680: accuracy:0.97 loss: 8.149822\n",
      "4690: accuracy:1.0 loss: 1.5230739\n",
      "4700: accuracy:0.96 loss: 10.8229\n",
      "4700: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9736 test loss: 10.702861\n",
      "4710: accuracy:0.99 loss: 2.461666\n",
      "4720: accuracy:1.0 loss: 0.6747429\n",
      "4730: accuracy:0.99 loss: 3.4089427\n",
      "4740: accuracy:1.0 loss: 1.0090492\n",
      "4750: accuracy:0.99 loss: 1.6729718\n",
      "4750: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9786 test loss: 8.818778\n",
      "4760: accuracy:0.99 loss: 5.8866997\n",
      "4770: accuracy:0.98 loss: 6.9072566\n",
      "4780: accuracy:0.99 loss: 5.225614\n",
      "4790: accuracy:0.97 loss: 14.425896\n",
      "4800: accuracy:0.97 loss: 3.0164618\n",
      "4800: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.978 test loss: 9.667037\n",
      "4810: accuracy:0.99 loss: 2.9962103\n",
      "4820: accuracy:0.99 loss: 2.6710913\n",
      "4830: accuracy:0.99 loss: 6.309139\n",
      "4840: accuracy:0.99 loss: 4.0150657\n",
      "4850: accuracy:0.99 loss: 1.472471\n",
      "4850: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9747 test loss: 10.844997\n",
      "4860: accuracy:0.97 loss: 8.340752\n",
      "4870: accuracy:0.99 loss: 1.1015155\n",
      "4880: accuracy:1.0 loss: 0.7317636\n",
      "4890: accuracy:0.97 loss: 10.065475\n",
      "4900: accuracy:0.98 loss: 4.8864617\n",
      "4900: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9796 test loss: 7.5657473\n",
      "4910: accuracy:0.99 loss: 3.0774338\n",
      "4920: accuracy:1.0 loss: 0.39887404\n",
      "4930: accuracy:0.99 loss: 5.649086\n",
      "4940: accuracy:0.99 loss: 1.4248945\n",
      "4950: accuracy:0.98 loss: 8.705711\n",
      "4950: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9762 test loss: 9.4875765\n",
      "4960: accuracy:0.99 loss: 4.715526\n",
      "4970: accuracy:1.0 loss: 0.08101367\n",
      "4980: accuracy:0.99 loss: 4.7459617\n",
      "4990: accuracy:1.0 loss: 1.2662835\n",
      "5000: accuracy:1.0 loss: 0.6126044\n",
      "5000: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9791 test loss: 8.269325\n",
      "5010: accuracy:1.0 loss: 2.212937\n",
      "5020: accuracy:0.99 loss: 4.5526166\n",
      "5030: accuracy:0.99 loss: 1.5312339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5040: accuracy:0.99 loss: 3.0690272\n",
      "5050: accuracy:0.99 loss: 2.6277704\n",
      "5050: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9796 test loss: 8.7342005\n",
      "5060: accuracy:0.99 loss: 3.110399\n",
      "5070: accuracy:0.98 loss: 6.936868\n",
      "5080: accuracy:0.98 loss: 9.880857\n",
      "5090: accuracy:0.99 loss: 1.5656788\n",
      "5100: accuracy:1.0 loss: 0.512315\n",
      "5100: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9782 test loss: 7.94152\n",
      "5110: accuracy:0.99 loss: 3.423538\n",
      "5120: accuracy:1.0 loss: 0.8158613\n",
      "5130: accuracy:0.99 loss: 2.0779831\n",
      "5140: accuracy:0.99 loss: 6.501456\n",
      "5150: accuracy:1.0 loss: 0.75038964\n",
      "5150: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9789 test loss: 8.95362\n",
      "5160: accuracy:0.99 loss: 7.653099\n",
      "5170: accuracy:0.98 loss: 5.584472\n",
      "5180: accuracy:0.99 loss: 1.0061225\n",
      "5190: accuracy:0.97 loss: 7.3625846\n",
      "5200: accuracy:1.0 loss: 0.7073867\n",
      "5200: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9775 test loss: 9.524117\n",
      "5210: accuracy:0.99 loss: 2.090539\n",
      "5220: accuracy:1.0 loss: 1.1430824\n",
      "5230: accuracy:1.0 loss: 1.6115464\n",
      "5240: accuracy:0.99 loss: 4.573464\n",
      "5250: accuracy:0.99 loss: 1.515434\n",
      "5250: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9777 test loss: 9.232414\n",
      "5260: accuracy:0.99 loss: 2.3750184\n",
      "5270: accuracy:1.0 loss: 0.10623419\n",
      "5280: accuracy:0.99 loss: 4.2999554\n",
      "5290: accuracy:1.0 loss: 0.34398696\n",
      "5300: accuracy:1.0 loss: 0.9942247\n",
      "5300: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9689 test loss: 13.258661\n",
      "5310: accuracy:0.98 loss: 5.3575454\n",
      "5320: accuracy:1.0 loss: 0.39557758\n",
      "5330: accuracy:0.99 loss: 5.65796\n",
      "5340: accuracy:0.97 loss: 6.75247\n",
      "5350: accuracy:0.99 loss: 6.1052837\n",
      "5350: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9761 test loss: 10.718705\n",
      "5360: accuracy:0.98 loss: 6.770461\n",
      "5370: accuracy:1.0 loss: 1.8967252\n",
      "5380: accuracy:0.99 loss: 8.107122\n",
      "5390: accuracy:0.99 loss: 1.5657965\n",
      "5400: accuracy:0.96 loss: 10.632146\n",
      "5400: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9767 test loss: 9.6428585\n",
      "5410: accuracy:0.97 loss: 5.4800873\n",
      "5420: accuracy:0.99 loss: 2.454541\n",
      "5430: accuracy:1.0 loss: 0.68230903\n",
      "5440: accuracy:0.98 loss: 4.3480425\n",
      "5450: accuracy:0.99 loss: 2.625665\n",
      "5450: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9788 test loss: 8.810097\n",
      "5460: accuracy:0.99 loss: 0.9336228\n",
      "5470: accuracy:1.0 loss: 0.68343073\n",
      "5480: accuracy:1.0 loss: 0.61724854\n",
      "5490: accuracy:1.0 loss: 0.37454733\n",
      "5500: accuracy:1.0 loss: 0.11393352\n",
      "5500: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9752 test loss: 10.441772\n",
      "5510: accuracy:1.0 loss: 1.0145969\n",
      "5520: accuracy:0.99 loss: 10.509211\n",
      "5530: accuracy:0.99 loss: 3.0338037\n",
      "5540: accuracy:1.0 loss: 0.09705373\n",
      "5550: accuracy:1.0 loss: 0.87862146\n",
      "5550: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9772 test loss: 10.006566\n",
      "5560: accuracy:0.99 loss: 1.539848\n",
      "5570: accuracy:0.99 loss: 2.8043985\n",
      "5580: accuracy:0.99 loss: 1.948772\n",
      "5590: accuracy:1.0 loss: 0.7218291\n",
      "5600: accuracy:1.0 loss: 0.24639782\n",
      "5600: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9749 test loss: 10.906852\n",
      "5610: accuracy:1.0 loss: 0.21900977\n",
      "5620: accuracy:0.99 loss: 4.3836803\n",
      "5630: accuracy:1.0 loss: 0.15125316\n",
      "5640: accuracy:0.99 loss: 1.88517\n",
      "5650: accuracy:1.0 loss: 1.3859758\n",
      "5650: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9808 test loss: 8.549785\n",
      "5660: accuracy:0.99 loss: 3.068069\n",
      "5670: accuracy:0.99 loss: 2.0713937\n",
      "5680: accuracy:0.99 loss: 5.178687\n",
      "5690: accuracy:0.98 loss: 7.1513543\n",
      "5700: accuracy:1.0 loss: 0.19694957\n",
      "5700: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9784 test loss: 9.364593\n",
      "5710: accuracy:1.0 loss: 1.1842084\n",
      "5720: accuracy:1.0 loss: 0.8452063\n",
      "5730: accuracy:0.99 loss: 1.4343137\n",
      "5740: accuracy:0.98 loss: 4.497527\n",
      "5750: accuracy:0.98 loss: 3.0255406\n",
      "5750: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9776 test loss: 9.530103\n",
      "5760: accuracy:0.99 loss: 4.176718\n",
      "5770: accuracy:1.0 loss: 1.1419951\n",
      "5780: accuracy:0.99 loss: 4.6509986\n",
      "5790: accuracy:0.99 loss: 4.4484763\n",
      "5800: accuracy:1.0 loss: 0.8292655\n",
      "5800: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.976 test loss: 10.358826\n",
      "5810: accuracy:1.0 loss: 0.7553437\n",
      "5820: accuracy:0.94 loss: 16.861855\n",
      "5830: accuracy:1.0 loss: 1.0947224\n",
      "5840: accuracy:1.0 loss: 1.821379\n",
      "5850: accuracy:1.0 loss: 1.2525967\n",
      "5850: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9749 test loss: 10.139232\n",
      "5860: accuracy:0.98 loss: 4.329277\n",
      "5870: accuracy:0.99 loss: 1.5559534\n",
      "5880: accuracy:0.98 loss: 3.8840468\n",
      "5890: accuracy:1.0 loss: 0.81558496\n",
      "5900: accuracy:0.99 loss: 5.8717194\n",
      "5900: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9766 test loss: 9.888407\n",
      "5910: accuracy:0.99 loss: 2.8962126\n",
      "5920: accuracy:0.99 loss: 4.06528\n",
      "5930: accuracy:0.99 loss: 5.8256974\n",
      "5940: accuracy:0.98 loss: 6.08296\n",
      "5950: accuracy:0.99 loss: 7.4743047\n",
      "5950: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9762 test loss: 8.971512\n",
      "5960: accuracy:0.99 loss: 2.2427576\n",
      "5970: accuracy:0.99 loss: 2.6972532\n",
      "5980: accuracy:1.0 loss: 0.103121236\n",
      "5990: accuracy:0.99 loss: 6.8427744\n",
      "6000: accuracy:1.0 loss: 0.12456638\n",
      "6000: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9767 test loss: 9.298283\n",
      "6010: accuracy:0.99 loss: 4.280127\n",
      "6020: accuracy:1.0 loss: 0.7122091\n",
      "6030: accuracy:0.99 loss: 4.605727\n",
      "6040: accuracy:0.98 loss: 9.890441\n",
      "6050: accuracy:1.0 loss: 0.2739246\n",
      "6050: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.978 test loss: 9.0747175\n",
      "6060: accuracy:1.0 loss: 0.37256783\n",
      "6070: accuracy:1.0 loss: 0.70587087\n",
      "6080: accuracy:0.99 loss: 2.0007832\n",
      "6090: accuracy:0.99 loss: 5.2606616\n",
      "6100: accuracy:1.0 loss: 0.70442605\n",
      "6100: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9801 test loss: 8.524419\n",
      "6110: accuracy:1.0 loss: 0.2483166\n",
      "6120: accuracy:0.98 loss: 5.585933\n",
      "6130: accuracy:1.0 loss: 0.2508501\n",
      "6140: accuracy:0.98 loss: 3.4800887\n",
      "6150: accuracy:1.0 loss: 0.11633645\n",
      "6150: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9812 test loss: 8.932713\n",
      "6160: accuracy:0.99 loss: 3.546801\n",
      "6170: accuracy:0.96 loss: 10.65076\n",
      "6180: accuracy:0.97 loss: 7.939559\n",
      "6190: accuracy:0.99 loss: 3.2094982\n",
      "6200: accuracy:0.98 loss: 8.037269\n",
      "6200: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9787 test loss: 9.332955\n",
      "6210: accuracy:1.0 loss: 0.23368672\n",
      "6220: accuracy:0.97 loss: 8.4796\n",
      "6230: accuracy:1.0 loss: 0.21671194\n",
      "6240: accuracy:1.0 loss: 0.4408672\n",
      "6250: accuracy:0.99 loss: 3.4337142\n",
      "6250: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9765 test loss: 10.248857\n",
      "6260: accuracy:0.98 loss: 4.9870462\n",
      "6270: accuracy:0.99 loss: 1.0498742\n",
      "6280: accuracy:0.99 loss: 2.7735052\n",
      "6290: accuracy:0.99 loss: 6.3673177\n",
      "6300: accuracy:0.99 loss: 7.835602\n",
      "6300: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9763 test loss: 9.62247\n",
      "6310: accuracy:1.0 loss: 0.2564649\n",
      "6320: accuracy:0.99 loss: 1.6658505\n",
      "6330: accuracy:1.0 loss: 0.2405383\n",
      "6340: accuracy:0.99 loss: 1.2323513\n",
      "6350: accuracy:1.0 loss: 0.07204823\n",
      "6350: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9775 test loss: 9.973555\n",
      "6360: accuracy:1.0 loss: 0.4113613\n",
      "6370: accuracy:1.0 loss: 2.7732656\n",
      "6380: accuracy:0.99 loss: 3.7513568\n",
      "6390: accuracy:0.99 loss: 1.6775653\n",
      "6400: accuracy:0.99 loss: 4.308151\n",
      "6400: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.978 test loss: 10.8724985\n",
      "6410: accuracy:0.99 loss: 6.59472\n",
      "6420: accuracy:0.99 loss: 2.886655\n",
      "6430: accuracy:0.99 loss: 5.433116\n",
      "6440: accuracy:0.98 loss: 8.9242325\n",
      "6450: accuracy:1.0 loss: 0.40695938\n",
      "6450: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9769 test loss: 9.409466\n",
      "6460: accuracy:0.99 loss: 4.162869\n",
      "6470: accuracy:1.0 loss: 1.3016217\n",
      "6480: accuracy:0.99 loss: 3.3388295\n",
      "6490: accuracy:0.97 loss: 4.750378\n",
      "6500: accuracy:0.99 loss: 3.4462485\n",
      "6500: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9788 test loss: 9.512233\n",
      "6510: accuracy:0.99 loss: 7.191973\n",
      "6520: accuracy:0.98 loss: 9.008247\n",
      "6530: accuracy:1.0 loss: 0.48203772\n",
      "6540: accuracy:0.98 loss: 4.5593348\n",
      "6550: accuracy:0.98 loss: 3.7480733\n",
      "6550: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9695 test loss: 13.258192\n",
      "6560: accuracy:0.99 loss: 13.915822\n",
      "6570: accuracy:0.99 loss: 3.0528934\n",
      "6580: accuracy:0.99 loss: 0.92545396\n",
      "6590: accuracy:1.0 loss: 0.49050668\n",
      "6600: accuracy:0.99 loss: 2.1959062\n",
      "6600: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9765 test loss: 10.571729\n",
      "6610: accuracy:0.99 loss: 3.4657915\n",
      "6620: accuracy:1.0 loss: 0.9093728\n",
      "6630: accuracy:0.98 loss: 6.1776996\n",
      "6640: accuracy:1.0 loss: 0.68438995\n",
      "6650: accuracy:1.0 loss: 0.57847196\n",
      "6650: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9775 test loss: 10.172801\n",
      "6660: accuracy:0.98 loss: 4.4649673\n",
      "6670: accuracy:0.99 loss: 1.9787858\n",
      "6680: accuracy:0.99 loss: 3.9004366\n",
      "6690: accuracy:0.98 loss: 5.703633\n",
      "6700: accuracy:0.99 loss: 2.7014363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6700: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9807 test loss: 10.107842\n",
      "6710: accuracy:1.0 loss: 0.050313544\n",
      "6720: accuracy:1.0 loss: 0.026782246\n",
      "6730: accuracy:0.99 loss: 2.2255015\n",
      "6740: accuracy:0.99 loss: 3.32897\n",
      "6750: accuracy:1.0 loss: 0.6554198\n",
      "6750: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9794 test loss: 10.409085\n",
      "6760: accuracy:0.99 loss: 2.6324484\n",
      "6770: accuracy:0.99 loss: 0.9689358\n",
      "6780: accuracy:0.99 loss: 1.6063653\n",
      "6790: accuracy:0.99 loss: 3.4439876\n",
      "6800: accuracy:0.99 loss: 2.2258627\n",
      "6800: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.981 test loss: 9.232416\n",
      "6810: accuracy:1.0 loss: 0.20232333\n",
      "6820: accuracy:0.98 loss: 9.077954\n",
      "6830: accuracy:1.0 loss: 0.15170091\n",
      "6840: accuracy:0.99 loss: 1.5706865\n",
      "6850: accuracy:1.0 loss: 1.3504101\n",
      "6850: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9763 test loss: 9.331473\n",
      "6860: accuracy:1.0 loss: 0.1578116\n",
      "6870: accuracy:1.0 loss: 1.4055991\n",
      "6880: accuracy:1.0 loss: 0.46712527\n",
      "6890: accuracy:1.0 loss: 1.419308\n",
      "6900: accuracy:1.0 loss: 0.24162535\n",
      "6900: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9793 test loss: 9.386476\n",
      "6910: accuracy:1.0 loss: 0.2971972\n",
      "6920: accuracy:0.98 loss: 8.160525\n",
      "6930: accuracy:1.0 loss: 0.07506612\n",
      "6940: accuracy:0.98 loss: 13.790011\n",
      "6950: accuracy:0.98 loss: 10.355923\n",
      "6950: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9791 test loss: 9.467532\n",
      "6960: accuracy:1.0 loss: 1.0789465\n",
      "6970: accuracy:1.0 loss: 0.40689948\n",
      "6980: accuracy:1.0 loss: 1.1628809\n",
      "6990: accuracy:1.0 loss: 1.3089007\n",
      "7000: accuracy:0.98 loss: 2.708388\n",
      "7000: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9788 test loss: 9.955705\n",
      "7010: accuracy:1.0 loss: 0.22646219\n",
      "7020: accuracy:0.99 loss: 1.9718845\n",
      "7030: accuracy:0.99 loss: 3.0889628\n",
      "7040: accuracy:0.99 loss: 2.5939217\n",
      "7050: accuracy:1.0 loss: 1.2322065\n",
      "7050: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9722 test loss: 12.379861\n",
      "7060: accuracy:0.99 loss: 7.9991684\n",
      "7070: accuracy:0.99 loss: 2.1544445\n",
      "7080: accuracy:1.0 loss: 0.25621283\n",
      "7090: accuracy:0.99 loss: 3.2480068\n",
      "7100: accuracy:0.98 loss: 12.31235\n",
      "7100: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9761 test loss: 11.064299\n",
      "7110: accuracy:0.98 loss: 8.135872\n",
      "7120: accuracy:1.0 loss: 0.33686\n",
      "7130: accuracy:1.0 loss: 1.0946147\n",
      "7140: accuracy:1.0 loss: 0.84281015\n",
      "7150: accuracy:0.99 loss: 5.332042\n",
      "7150: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9766 test loss: 10.350059\n",
      "7160: accuracy:1.0 loss: 1.0580169\n",
      "7170: accuracy:0.99 loss: 1.6559181\n",
      "7180: accuracy:0.98 loss: 8.664045\n",
      "7190: accuracy:1.0 loss: 0.29743874\n",
      "7200: accuracy:0.98 loss: 9.245019\n",
      "7200: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9797 test loss: 8.881707\n",
      "7210: accuracy:0.99 loss: 4.8596916\n",
      "7220: accuracy:1.0 loss: 0.26897427\n",
      "7230: accuracy:1.0 loss: 0.25567436\n",
      "7240: accuracy:0.99 loss: 4.1080537\n",
      "7250: accuracy:0.99 loss: 1.1096413\n",
      "7250: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9768 test loss: 10.15095\n",
      "7260: accuracy:1.0 loss: 0.6367249\n",
      "7270: accuracy:0.99 loss: 1.0772011\n",
      "7280: accuracy:0.99 loss: 1.1953971\n",
      "7290: accuracy:0.99 loss: 1.7836643\n",
      "7300: accuracy:0.99 loss: 5.9054127\n",
      "7300: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9779 test loss: 11.40013\n",
      "7310: accuracy:0.99 loss: 1.0944731\n",
      "7320: accuracy:0.98 loss: 3.5911582\n",
      "7330: accuracy:1.0 loss: 1.4338754\n",
      "7340: accuracy:0.99 loss: 2.0540957\n",
      "7350: accuracy:1.0 loss: 0.364657\n",
      "7350: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9798 test loss: 9.651083\n",
      "7360: accuracy:1.0 loss: 1.3269452\n",
      "7370: accuracy:0.99 loss: 2.402257\n",
      "7380: accuracy:1.0 loss: 0.23678687\n",
      "7390: accuracy:0.97 loss: 6.460097\n",
      "7400: accuracy:1.0 loss: 0.08893079\n",
      "7400: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9783 test loss: 10.39072\n",
      "7410: accuracy:0.99 loss: 3.9225366\n",
      "7420: accuracy:1.0 loss: 0.026433993\n",
      "7430: accuracy:0.99 loss: 5.61153\n",
      "7440: accuracy:0.97 loss: 10.551627\n",
      "7450: accuracy:1.0 loss: 0.013746769\n",
      "7450: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.979 test loss: 10.076692\n",
      "7460: accuracy:0.99 loss: 4.7494354\n",
      "7470: accuracy:1.0 loss: 0.6801277\n",
      "7480: accuracy:1.0 loss: 0.3819559\n",
      "7490: accuracy:0.99 loss: 4.1726665\n",
      "7500: accuracy:0.98 loss: 2.2074606\n",
      "7500: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9786 test loss: 10.023556\n",
      "7510: accuracy:1.0 loss: 0.16513239\n",
      "7520: accuracy:1.0 loss: 0.22231825\n",
      "7530: accuracy:0.99 loss: 5.508811\n",
      "7540: accuracy:0.98 loss: 8.466184\n",
      "7550: accuracy:1.0 loss: 0.33047533\n",
      "7550: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9768 test loss: 10.725414\n",
      "7560: accuracy:0.99 loss: 1.1572862\n",
      "7570: accuracy:0.99 loss: 6.078253\n",
      "7580: accuracy:1.0 loss: 0.66889685\n",
      "7590: accuracy:1.0 loss: 0.5745443\n",
      "7600: accuracy:0.99 loss: 1.1141138\n",
      "7600: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9816 test loss: 9.084039\n",
      "7610: accuracy:1.0 loss: 0.15743788\n",
      "7620: accuracy:0.99 loss: 2.3569613\n",
      "7630: accuracy:1.0 loss: 1.6765409\n",
      "7640: accuracy:1.0 loss: 0.64902085\n",
      "7650: accuracy:0.97 loss: 11.408598\n",
      "7650: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9757 test loss: 11.708684\n",
      "7660: accuracy:0.99 loss: 5.4128847\n",
      "7670: accuracy:0.98 loss: 4.034485\n",
      "7680: accuracy:1.0 loss: 0.33544374\n",
      "7690: accuracy:1.0 loss: 1.2177603\n",
      "7700: accuracy:1.0 loss: 0.565424\n",
      "7700: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9782 test loss: 10.017619\n",
      "7710: accuracy:1.0 loss: 0.95394075\n",
      "7720: accuracy:0.99 loss: 2.2357185\n",
      "7730: accuracy:0.99 loss: 2.0771525\n",
      "7740: accuracy:0.99 loss: 1.5189551\n",
      "7750: accuracy:0.99 loss: 3.3064258\n",
      "7750: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9804 test loss: 9.426958\n",
      "7760: accuracy:0.99 loss: 3.3021283\n",
      "7770: accuracy:1.0 loss: 1.1427383\n",
      "7780: accuracy:1.0 loss: 0.21562204\n",
      "7790: accuracy:1.0 loss: 0.021610256\n",
      "7800: accuracy:0.99 loss: 3.4299076\n",
      "7800: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9729 test loss: 12.123831\n",
      "7810: accuracy:0.99 loss: 1.1449263\n",
      "7820: accuracy:1.0 loss: 0.8710305\n",
      "7830: accuracy:0.99 loss: 2.244315\n",
      "7840: accuracy:1.0 loss: 1.0982858\n",
      "7850: accuracy:0.99 loss: 4.645262\n",
      "7850: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9771 test loss: 10.421104\n",
      "7860: accuracy:1.0 loss: 0.08473468\n",
      "7870: accuracy:1.0 loss: 0.14236543\n",
      "7880: accuracy:0.99 loss: 2.048032\n",
      "7890: accuracy:1.0 loss: 0.103568844\n",
      "7900: accuracy:0.99 loss: 2.3344362\n",
      "7900: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9779 test loss: 10.870067\n",
      "7910: accuracy:0.99 loss: 1.5775187\n",
      "7920: accuracy:1.0 loss: 0.008534617\n",
      "7930: accuracy:1.0 loss: 0.12462428\n",
      "7940: accuracy:1.0 loss: 1.003757\n",
      "7950: accuracy:1.0 loss: 0.25612375\n",
      "7950: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.976 test loss: 10.939954\n",
      "7960: accuracy:1.0 loss: 0.04549748\n",
      "7970: accuracy:1.0 loss: 0.15889639\n",
      "7980: accuracy:0.99 loss: 1.2764244\n",
      "7990: accuracy:1.0 loss: 0.93406624\n",
      "8000: accuracy:1.0 loss: 1.1560495\n",
      "8000: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9791 test loss: 9.885079\n",
      "8010: accuracy:0.99 loss: 1.9631352\n",
      "8020: accuracy:1.0 loss: 0.85052794\n",
      "8030: accuracy:0.99 loss: 1.5925298\n",
      "8040: accuracy:1.0 loss: 0.36722687\n",
      "8050: accuracy:1.0 loss: 0.032468352\n",
      "8050: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9783 test loss: 11.141754\n",
      "8060: accuracy:0.97 loss: 4.962987\n",
      "8070: accuracy:0.99 loss: 0.80037576\n",
      "8080: accuracy:0.98 loss: 5.0811696\n",
      "8090: accuracy:1.0 loss: 0.7759749\n",
      "8100: accuracy:0.98 loss: 7.8072352\n",
      "8100: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9794 test loss: 9.585164\n",
      "8110: accuracy:1.0 loss: 0.8076005\n",
      "8120: accuracy:1.0 loss: 0.6431876\n",
      "8130: accuracy:1.0 loss: 0.47669044\n",
      "8140: accuracy:1.0 loss: 0.30765158\n",
      "8150: accuracy:0.99 loss: 2.158341\n",
      "8150: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9764 test loss: 10.242022\n",
      "8160: accuracy:0.94 loss: 17.435003\n",
      "8170: accuracy:0.99 loss: 2.0409725\n",
      "8180: accuracy:1.0 loss: 1.1635507\n",
      "8190: accuracy:0.99 loss: 4.4012957\n",
      "8200: accuracy:1.0 loss: 0.86952335\n",
      "8200: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9771 test loss: 10.600661\n",
      "8210: accuracy:1.0 loss: 0.119503856\n",
      "8220: accuracy:1.0 loss: 0.2504233\n",
      "8230: accuracy:1.0 loss: 0.23071049\n",
      "8240: accuracy:0.99 loss: 1.2563776\n",
      "8250: accuracy:0.99 loss: 3.7159762\n",
      "8250: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9765 test loss: 11.490021\n",
      "8260: accuracy:0.98 loss: 6.9812574\n",
      "8270: accuracy:0.99 loss: 1.5061542\n",
      "8280: accuracy:1.0 loss: 0.6232841\n",
      "8290: accuracy:1.0 loss: 0.49782306\n",
      "8300: accuracy:0.99 loss: 1.8890377\n",
      "8300: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9772 test loss: 10.2516365\n",
      "8310: accuracy:0.99 loss: 4.826683\n",
      "8320: accuracy:0.99 loss: 1.7751124\n",
      "8330: accuracy:0.98 loss: 6.0339375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8340: accuracy:0.97 loss: 11.837314\n",
      "8350: accuracy:0.99 loss: 4.8809085\n",
      "8350: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9782 test loss: 9.067119\n",
      "8360: accuracy:0.99 loss: 1.8190446\n",
      "8370: accuracy:0.99 loss: 2.201322\n",
      "8380: accuracy:0.99 loss: 1.277754\n",
      "8390: accuracy:0.99 loss: 1.8107865\n",
      "8400: accuracy:0.99 loss: 1.1623013\n",
      "8400: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.98 test loss: 9.233768\n",
      "8410: accuracy:0.99 loss: 1.4212637\n",
      "8420: accuracy:0.98 loss: 9.909768\n",
      "8430: accuracy:1.0 loss: 0.17168945\n",
      "8440: accuracy:0.98 loss: 2.947411\n",
      "8450: accuracy:1.0 loss: 0.12269426\n",
      "8450: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9803 test loss: 9.803899\n",
      "8460: accuracy:0.98 loss: 6.192025\n",
      "8470: accuracy:0.99 loss: 7.296911\n",
      "8480: accuracy:1.0 loss: 0.55272925\n",
      "8490: accuracy:1.0 loss: 0.078543775\n",
      "8500: accuracy:1.0 loss: 0.29625088\n",
      "8500: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9774 test loss: 10.875262\n",
      "8510: accuracy:1.0 loss: 0.026577117\n",
      "8520: accuracy:1.0 loss: 0.04447958\n",
      "8530: accuracy:1.0 loss: 0.10332181\n",
      "8540: accuracy:1.0 loss: 0.58692986\n",
      "8550: accuracy:1.0 loss: 0.03416755\n",
      "8550: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9793 test loss: 10.318794\n",
      "8560: accuracy:1.0 loss: 2.4947162\n",
      "8570: accuracy:1.0 loss: 0.07568149\n",
      "8580: accuracy:1.0 loss: 0.091266595\n",
      "8590: accuracy:0.97 loss: 8.659706\n",
      "8600: accuracy:0.99 loss: 1.8499037\n",
      "8600: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9796 test loss: 9.891815\n",
      "8610: accuracy:0.98 loss: 3.041144\n",
      "8620: accuracy:1.0 loss: 0.47613922\n",
      "8630: accuracy:1.0 loss: 0.7503893\n",
      "8640: accuracy:1.0 loss: 0.0820848\n",
      "8650: accuracy:0.98 loss: 3.9923213\n",
      "8650: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9777 test loss: 10.094647\n",
      "8660: accuracy:0.99 loss: 2.5352206\n",
      "8670: accuracy:0.99 loss: 1.1664026\n",
      "8680: accuracy:1.0 loss: 0.9150318\n",
      "8690: accuracy:1.0 loss: 0.33245343\n",
      "8700: accuracy:1.0 loss: 0.94919366\n",
      "8700: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9764 test loss: 11.929974\n",
      "8710: accuracy:1.0 loss: 0.31570017\n",
      "8720: accuracy:1.0 loss: 0.42895883\n",
      "8730: accuracy:1.0 loss: 1.4828281\n",
      "8740: accuracy:0.98 loss: 7.6634808\n",
      "8750: accuracy:1.0 loss: 0.3536662\n",
      "8750: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9777 test loss: 10.547854\n",
      "8760: accuracy:0.99 loss: 2.3686728\n",
      "8770: accuracy:0.99 loss: 4.689266\n",
      "8780: accuracy:1.0 loss: 0.51143\n",
      "8790: accuracy:0.99 loss: 3.4701104\n",
      "8800: accuracy:0.99 loss: 1.191935\n",
      "8800: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9786 test loss: 9.727136\n",
      "8810: accuracy:0.99 loss: 1.7453656\n",
      "8820: accuracy:0.98 loss: 6.874773\n",
      "8830: accuracy:1.0 loss: 0.17361201\n",
      "8840: accuracy:0.99 loss: 5.111113\n",
      "8850: accuracy:1.0 loss: 0.7106109\n",
      "8850: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9774 test loss: 11.768492\n",
      "8860: accuracy:0.97 loss: 6.8260365\n",
      "8870: accuracy:1.0 loss: 0.52919054\n",
      "8880: accuracy:1.0 loss: 0.078060836\n",
      "8890: accuracy:1.0 loss: 1.9267361\n",
      "8900: accuracy:1.0 loss: 0.07950823\n",
      "8900: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9782 test loss: 10.353742\n",
      "8910: accuracy:0.99 loss: 2.3428106\n",
      "8920: accuracy:1.0 loss: 0.18298075\n",
      "8930: accuracy:0.99 loss: 2.8099678\n",
      "8940: accuracy:1.0 loss: 0.025584126\n",
      "8950: accuracy:0.99 loss: 1.2773927\n",
      "8950: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9783 test loss: 12.061894\n",
      "8960: accuracy:0.97 loss: 12.030225\n",
      "8970: accuracy:0.98 loss: 3.9771442\n",
      "8980: accuracy:0.99 loss: 3.7795286\n",
      "8990: accuracy:0.98 loss: 4.941702\n",
      "9000: accuracy:0.99 loss: 1.5767878\n",
      "9000: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9759 test loss: 11.62623\n",
      "9010: accuracy:1.0 loss: 0.56146854\n",
      "9020: accuracy:1.0 loss: 0.90790504\n",
      "9030: accuracy:1.0 loss: 0.75198925\n",
      "9040: accuracy:1.0 loss: 0.11580392\n",
      "9050: accuracy:1.0 loss: 0.26312426\n",
      "9050: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9804 test loss: 9.715424\n",
      "9060: accuracy:1.0 loss: 0.13775651\n",
      "9070: accuracy:1.0 loss: 0.036863614\n",
      "9080: accuracy:1.0 loss: 0.478883\n",
      "9090: accuracy:0.99 loss: 1.682707\n",
      "9100: accuracy:0.98 loss: 3.7269578\n",
      "9100: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9768 test loss: 11.099722\n",
      "9110: accuracy:0.98 loss: 7.3895226\n",
      "9120: accuracy:1.0 loss: 0.22658268\n",
      "9130: accuracy:1.0 loss: 0.12710743\n",
      "9140: accuracy:1.0 loss: 0.11242315\n",
      "9150: accuracy:0.99 loss: 1.773867\n",
      "9150: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9751 test loss: 10.013018\n",
      "9160: accuracy:0.99 loss: 1.9351974\n",
      "9170: accuracy:0.99 loss: 3.0719244\n",
      "9180: accuracy:1.0 loss: 0.076249026\n",
      "9190: accuracy:0.98 loss: 5.6708426\n",
      "9200: accuracy:0.98 loss: 4.030825\n",
      "9200: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9784 test loss: 10.027309\n",
      "9210: accuracy:0.99 loss: 1.6854873\n",
      "9220: accuracy:0.98 loss: 4.601999\n",
      "9230: accuracy:1.0 loss: 0.0147739835\n",
      "9240: accuracy:0.99 loss: 1.5892853\n",
      "9250: accuracy:1.0 loss: 0.22806698\n",
      "9250: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9775 test loss: 11.148613\n",
      "9260: accuracy:0.99 loss: 4.761108\n",
      "9270: accuracy:1.0 loss: 0.015766205\n",
      "9280: accuracy:0.99 loss: 2.6601567\n",
      "9290: accuracy:0.99 loss: 2.6619182\n",
      "9300: accuracy:1.0 loss: 0.23996322\n",
      "9300: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9759 test loss: 11.127275\n",
      "9310: accuracy:1.0 loss: 0.2044165\n",
      "9320: accuracy:0.97 loss: 5.9906087\n",
      "9330: accuracy:1.0 loss: 0.20738353\n",
      "9340: accuracy:1.0 loss: 0.22379759\n",
      "9350: accuracy:0.99 loss: 2.114582\n",
      "9350: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9788 test loss: 9.409562\n",
      "9360: accuracy:0.98 loss: 3.270309\n",
      "9370: accuracy:1.0 loss: 0.62303436\n",
      "9380: accuracy:1.0 loss: 0.44743204\n",
      "9390: accuracy:0.99 loss: 7.5589566\n",
      "9400: accuracy:0.99 loss: 2.1086087\n",
      "9400: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9783 test loss: 9.928379\n",
      "9410: accuracy:1.0 loss: 0.67262214\n",
      "9420: accuracy:0.99 loss: 1.0430758\n",
      "9430: accuracy:1.0 loss: 0.7311281\n",
      "9440: accuracy:1.0 loss: 0.4803901\n",
      "9450: accuracy:1.0 loss: 0.17302482\n",
      "9450: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9786 test loss: 10.876096\n",
      "9460: accuracy:0.98 loss: 2.6665363\n",
      "9470: accuracy:0.99 loss: 6.485603\n",
      "9480: accuracy:0.99 loss: 2.0038693\n",
      "9490: accuracy:1.0 loss: 0.024291428\n",
      "9500: accuracy:0.99 loss: 1.3097966\n",
      "9500: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9789 test loss: 10.487864\n",
      "9510: accuracy:0.98 loss: 2.6608908\n",
      "9520: accuracy:1.0 loss: 0.17938247\n",
      "9530: accuracy:1.0 loss: 0.21689448\n",
      "9540: accuracy:0.99 loss: 6.014354\n",
      "9550: accuracy:1.0 loss: 0.15285213\n",
      "9550: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9782 test loss: 10.588245\n",
      "9560: accuracy:0.98 loss: 6.4015045\n",
      "9570: accuracy:0.99 loss: 1.783078\n",
      "9580: accuracy:0.97 loss: 3.7829351\n",
      "9590: accuracy:0.99 loss: 2.380675\n",
      "9600: accuracy:0.99 loss: 8.494235\n",
      "9600: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9767 test loss: 10.188834\n",
      "9610: accuracy:1.0 loss: 1.2728328\n",
      "9620: accuracy:1.0 loss: 0.43084604\n",
      "9630: accuracy:1.0 loss: 0.41081676\n",
      "9640: accuracy:1.0 loss: 0.053145435\n",
      "9650: accuracy:0.99 loss: 2.955451\n",
      "9650: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9805 test loss: 10.40873\n",
      "9660: accuracy:1.0 loss: 0.23676357\n",
      "9670: accuracy:0.99 loss: 2.5687392\n",
      "9680: accuracy:1.0 loss: 0.31652784\n",
      "9690: accuracy:0.98 loss: 4.7561784\n",
      "9700: accuracy:0.99 loss: 3.180998\n",
      "9700: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9739 test loss: 14.798096\n",
      "9710: accuracy:1.0 loss: 0.042511687\n",
      "9720: accuracy:1.0 loss: 0.5121361\n",
      "9730: accuracy:0.99 loss: 4.5798974\n",
      "9740: accuracy:0.99 loss: 2.1486795\n",
      "9750: accuracy:1.0 loss: 0.4409138\n",
      "9750: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9746 test loss: 13.786106\n",
      "9760: accuracy:1.0 loss: 0.041045055\n",
      "9770: accuracy:1.0 loss: 0.21104635\n",
      "9780: accuracy:0.98 loss: 4.467246\n",
      "9790: accuracy:1.0 loss: 0.6991503\n",
      "9800: accuracy:1.0 loss: 0.17148663\n",
      "9800: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9803 test loss: 9.697678\n",
      "9810: accuracy:1.0 loss: 0.60556823\n",
      "9820: accuracy:1.0 loss: 0.26697662\n",
      "9830: accuracy:1.0 loss: 0.17871308\n",
      "9840: accuracy:1.0 loss: 0.12339658\n",
      "9850: accuracy:1.0 loss: 0.053345393\n",
      "9850: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9783 test loss: 10.229024\n",
      "9860: accuracy:1.0 loss: 0.61571074\n",
      "9870: accuracy:1.0 loss: 1.0525134\n",
      "9880: accuracy:0.99 loss: 4.8478813\n",
      "9890: accuracy:0.97 loss: 26.519361\n",
      "9900: accuracy:1.0 loss: 0.5513202\n",
      "9900: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9758 test loss: 14.391385\n",
      "9910: accuracy:1.0 loss: 0.08611034\n",
      "9920: accuracy:1.0 loss: 0.36077186\n",
      "9930: accuracy:0.98 loss: 6.686564\n",
      "9940: accuracy:0.99 loss: 2.9502842\n",
      "9950: accuracy:1.0 loss: 0.101540565\n",
      "9950: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9743 test loss: 13.182531\n",
      "9960: accuracy:1.0 loss: 1.3675253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9970: accuracy:0.96 loss: 8.420687\n",
      "9980: accuracy:1.0 loss: 0.12736322\n",
      "9990: accuracy:1.0 loss: 0.023139725\n",
      "10000: accuracy:1.0 loss: 0.1879934\n",
      "10000: $$$$$$$$$$$$$$$$$$$$$$$$ test accuracy:0.9794 test loss: 10.511571\n"
     ]
    }
   ],
   "source": [
    "# run this thang\n",
    "for i in range(10000+1): \n",
    "    training_step(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max test accuracy: 0.9816\n"
     ]
    }
   ],
   "source": [
    "print(\"max test accuracy: \" + str(max_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_log = np.array(train_loss_log)\n",
    "test_loss_log = np.array(test_loss_log)\n",
    "\n",
    "plt.plot(train_loss_log[:,0],train_loss_log[:,1])\n",
    "plt.plot(test_loss_log[:,0],test_loss_log[:,1])\n",
    "plt.ylim(top=30, bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_accuracy_log = np.array(train_accuracy_log)\n",
    "test_accuracy_log = np.array(test_accuracy_log)\n",
    "\n",
    "plt.plot(train_accuracy_log[:,0],train_accuracy_log[:,1])\n",
    "plt.plot(test_accuracy_log[:,0],test_accuracy_log[:,1])\n",
    "#plt.ylim(top = 1, bottom=.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
